{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0d18ad-ccfd-41cc-bd72-25bb97f668fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tflearn) (1.26.4)\n",
      "Requirement already satisfied: six in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tflearn) (1.16.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tflearn) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e20939-e443-498a-9f1b-1d7b910cb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\julia\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74642c8-8ab2-4860-bcbe-c4beab2f455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\julia\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (1.72.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\julia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\julia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\julia\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5637ae9-7c3b-4502-b4e2-9504a2699f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os         \n",
    "from random import shuffle \n",
    "from tqdm import tqdm      \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "TRAIN_DIR = \"C:/Users/julia/Pictures/train\"\n",
    "TEST_DIR = \"C:/Users/julia/Pictures/test\"\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "MODEL_NAME = 'dogs-vs-cats-convnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92abccc3-d4dc-401c-96bb-19b33d009abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    if word_label == 'cat':return[1,0]\n",
    "    elif word_label == 'dog':return[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13b1e090-d706-4a4c-afc6-3dc6d2b55c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label=label_img(img)\n",
    "        path=os.path.join(TRAIN_DIR, img)\n",
    "        img=cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    "def create_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img_data = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402ffdd9-61a2-4f9c-a20c-0e0d8e9cd75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6000/6000 [00:08<00:00, 676.55it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5b5ce4a-fc36-4dc0-897a-3444cda6b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "TRAIN_DIR = \"C:/Users/julia/Pictures/train\"\n",
    "IMG_SIZE = 50\n",
    "\n",
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    if word_label == 'cat': return [1, 0]\n",
    "    elif word_label == 'dog': return [0, 1]\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue  # 防止讀不到圖檔時出錯\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    "    \n",
    "    shuffle(training_data)\n",
    "\n",
    "    # 分開圖片和標籤\n",
    "    X = np.array([i[0] for i in training_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    Y = np.array([i[1] for i in training_data])\n",
    "\n",
    "    # 儲存\n",
    "    np.save('X.npy', X)\n",
    "    np.save('Y.npy', Y)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c39d146-9f2f-4bb9-aa2c-b095d54e5ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11941/11941 [00:17<00:00, 682.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3db93f9d-29ab-4289-bc0a-a2f6d9ff92d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11941/11941 [00:17<00:00, 669.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f7b56fa-31bd-433c-9bf3-33220ec0a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b761892a-fe5a-4423-aecb-9e91beefb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LR),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77d00f82-7584-4e10-8c6f-efd530d73b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'my_model.h5'\n",
    "\n",
    "if os.path.exists(MODEL_NAME):\n",
    "    model.load_weights(MODEL_NAME)\n",
    "    print('Model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369b4b2d-2716-4745-bbce-10ed5308d442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de57b7d7-5739-4864-a9be-2b17b875dfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-8000]\n",
    "test = train_data[-8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf0a995d-f944-44e9-b916-a3ed3cb9113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修正 test 資料，只留下合法圖片\n",
    "test_clean = [i for i in test if isinstance(i[0], np.ndarray) and i[0].shape == (IMG_SIZE, IMG_SIZE)]\n",
    "\n",
    "# 正確轉換\n",
    "test_x = np.array([i[0] for i in test_clean]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = np.array([i[1] for i in test_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5e46110-c2ba-474e-8b59-741381392719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (50,50,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m d \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m img_data, img_num \u001b[38;5;241m=\u001b[39m d\n\u001b[1;32m----> 9\u001b[0m data \u001b[38;5;241m=\u001b[39m img_data\u001b[38;5;241m.\u001b[39mreshape(IMG_SIZE, IMG_SIZE, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict([data])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (50,50,1)"
     ]
    }
   ],
   "source": [
    "print(img_data.shape)  # 看看現在的形狀\n",
    "img_data = np.array(img_data)  # 確保它是 NumPy 陣列\n",
    "img_data = img_data.squeeze()  # 去掉不必要的維度\n",
    "test_clean = [i for i in test_data if isinstance(i[0], np.ndarray) and i[0].shape == (IMG_SIZE, IMG_SIZE)]\n",
    "\n",
    "d = test_data[0]\n",
    "img_data, img_num = d\n",
    "\n",
    "data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "prediction = model.predict([data])[0]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img_data, cmap=\"gray\")\n",
    "print('Cat Possibility: {:5.2f}% \\nDog Possibility: {:5.2f}%'.format(prediction[0]*100, prediction[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad923b1e-f117-41bf-8a55-dbb78318a4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n",
      "Skipping invalid shape: ()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "for num, data in enumerate(test_data[:16]):\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    # 🔧 修正可能的巢狀 array 結構\n",
    "    img_data = np.array(img_data)\n",
    "    if img_data.shape == (1, IMG_SIZE, IMG_SIZE):\n",
    "        img_data = img_data[0]\n",
    "\n",
    "    if img_data.shape != (IMG_SIZE, IMG_SIZE):\n",
    "        print(f\"Skipping invalid shape: {img_data.shape}\")\n",
    "        continue\n",
    "    \n",
    "    y = fig.add_subplot(4, 4, num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    data = data / 255.0  # 正規化\n",
    "\n",
    "    model_out = model.predict(np.array([data]))[0]\n",
    "\n",
    "    if np.argmax(model_out) == 1: \n",
    "        str_label = 'Dog'\n",
    "    else:\n",
    "        str_label = 'Cat'\n",
    "        \n",
    "    y.imshow(orig, cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbbcc2-1438-483b-bdb7-4d46f8f6ad81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
